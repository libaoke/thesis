\chapter{利用竞价云加速大规模计算密集型并行任务处理}
\label{cha:task}

\section{本章概述}
\label{sec:no2_intro}
快速发展的云计算平台向其用户提供了大量充足的计算资源。在每一个普通的数据中心，每天通常有超过数千个服务器节点正在处理海量的并行计算任务以支撑大规模的信息检索、数据分析或科学计算等应用。在这样一个大规模的计算架构下，有效且健壮的任务处理框架是非常关键的。这样的计算框架应提供一种可行的方式方便使用者组织和使用底层巨大的计算资源池。具体来说，该计算框架应该能够促进应用开发和部署过程并提供QoS(Quality of Service)保证，同时负责调度程序在众多服务器节点上高效运行。近年来已经涌现了许多大规模分布式计算框架，最成功且有代表性的当属 MapReduce \cite{Dean:2004:MSD:1251254.1251264}。

本章聚焦于执行 SPMD 类任务的分布式处理框架，研究如何利用竞价云计算资源加速海量计算密集型任务的并行处理。计算密集型任务在执行的过程中需要大量的CPU时间，性能瓶颈存在于CPU能力上。另一类十分常见的并行处理任务是数据密集型任务，性能瓶颈存在于I/O带宽上。数据密集型任务在执行过程中会产生大量的数据I/O，通常需要处理TB级甚至是PB级的数据，例如：网页索引、数据统计分析等。MapReduce 就是针对这类数据密集型任务设计的计算框架。

在云计算平台中，同一台物理机上运行的多台虚拟机可能存在显著的性能差异。虽然虚拟化实现了对 CPU 和内存资源的有效隔离，物理机的 I/O 和网络带宽却是由其上的所有虚拟机共享的。这样的共享策略目的在于充分利用物理机的带宽资源，在其它虚拟机不使用 I/O 或 网络资源时可以独占全部带宽，在多个虚拟机竞争 I/O 或网络带宽时均分带宽资源。带宽的竞争可能来自云平台中的其它用户，也可能来自用户自身申请的其它虚拟机。另外，硬件、软件、配置等方面的错误也可能带来短时间的虚拟机性能下降。当使用的虚拟机数量达到一定规模时，这类不可预期的节点异常开始变得明显。这些异常节点（Outliers）是海量计算任务并行处理中最严重的性能杀手。异常节点的执行进度远远落后于相应的正常节点因而极大地拖延了整个作业的完成时间，进而影响了整个工作流的执行进度。

目前，针对异常节点问题在MapReduce计算框架有很多优化工作 \cite{Zaharia:2008:IMP:1855741.1855744, Ananthanarayanan:2010:ROM:1924943.1924962}。为了解决这一问题，许多计算框架都依靠任务调度器识别异常节点并通过投机执行策略在其他节点执行同一任务的副本来加速作业执行。该方法基于任务执行进度和对输入数据的读取量是相一致的假设，通过各个任务的I/O进度识别异常节点。显然，这个针对数据密集型并行任务的优化方案并不适合于计算密集型并行任务。

针对大规模计算密集型并行任务的特点，本章设计并实现了一个在ProActive计算框架上用来解决异常节点问题的海量计算密集型并行任务调度器。针对通过ProActive的封装实现并行的大量各类遗留代码（科学计算、工业设计、影像处理渲染等），该任务调度器使用二进制代码插桩技术实现了对程序执行的跟踪和异常节点的早期发现。通过尽早发现异常节点，基于多副本执行等策略执行同一任务避免拖慢整体作业进度。

将该方法应用于生产环境面临着如下挑战：1）二进制代码插桩可能带来不可接受的性能开销，例如：通过插桩函数入口以跟踪任务执行的位置。如果恰好插桩了很多频繁被调用的函数，运行时开销将无法接受。如何解决这个问题，实现低开销、自动化地二进制插桩？2）插桩得到的信息并不能预测任务的绝对执行进度，如何根据程序跟踪信息准确的找出异常节点？3）节点异常的偶发性使得该方法需要长期保留足够的计算资源用于副本执行，如何减少用于执行多副本策略的计算成本以使得该方法在长期收益上实际可用？

总体来说，该任务调度器的贡献主要在于：
\begin{enumerate}
\item 设计实现了一个利用竞价云的易于使用、高效低成本的海量计算密集型任务处理框架的任务调度器。
\item 提出了基于二进制代码插桩和聚类分析的海量计算密集型任务异常节点检测方法。该方法在极低的插桩运行时开销下实现了对异常节点的早期检测。
\item 利用多副本执行策略有效减少了作业完成时间，消除了异常节点带来的影响。实验结果表明对海量计算密集型并行任务的性能提升20\% $\sim$ 40\%，而利用竞价实例产生的成本开销只有约1\%。
\end{enumerate}

\section{ProActive 计算框架介绍}
ProActive \cite{ProActive} 并行计算套件由法国国家实验室INRIA开发，是一个开源的应用加速方案。它可以同高性能的云计算平台管理无缝集成，大大简化集群并行程序开发。ProActive 的并行分布式计算框架使用Java语言开发，没有对Java虚拟机（Java Virtual Machine）做任何修改。所以 ProActive的扩展性非常好，可以运行在任何支持标准Java环境的操作系统上。利用ProActive，用户可以轻松地加速和编排各种应用。

在云计算平台和集群等分布式计算环境中执行并行任务，需要统一地机制进行任务调度和资源管理。ProActive配备的是一个批处理式调度器 \cite{pascheduling}。该调度器向用户提供了资源的抽象。它允许用户提交包含一个或多个任务的作业，然后在可用的资源上执行这些任务。该调度器允许几个用户共享相同的资源池并处理分布式环境下引入的问题，如：任务执行失败、资源失效等。调度器也允许用户方便的杀掉一个指定的任务然后在另一个节点上重新执行该任务。

一般来说，调度器采用默认的先入先出（FIFO）优先级策略分配任务。用户可以根据任务的紧急程度提升其优先级，或者改变整个策略。在ProActive中，创建一个新的调度策略非常容易。用户只需实现策略，调度器可以通过策略接口执行新的调度策略。

ProActive的调度器同资源管理器 \cite{parm} 相连，资源管理器是一个跨网络的资源管理组件。它分配由ProActive节点（运行着ProActive Agent的Java虚拟机）表示的计算资源给管理任务工作流调度器，调度器将可使用的资源分发给各个任务。根据部署情况，资源管理器可以使用不同的标准检索计算资源，如SSH、LSF、OAR、gLite、EC2等等。基于调度器、资源管理器和其他组件，ProActive可以无需修改方便地运行在集群、网格、云计算平台以及各种形式的混合平台上。

\section{系统设计}
\label{sec:no2}
系统主要由两个组件构成（图 \ref{figure:no2arch}）：异常节点检测和任务执行加速。异常节点检测组件通过程序跟踪插桩工具和异常分析两个模块配合实现对大量并发任务中的异常节点检测。用户只需提供作业程序的二进制代码进行程序跟踪插桩，然后提交XML作业描述文件并使用插桩后的二进制代码作为执行文件。ProActive根据作业描述文件将计算任务分发到各个计算节点，各个节点执行插桩后的程序并返回任务执行跟踪信息。异常节点检测模块通过对跟踪信息的分析找出异常节点。如果存在异常节点，如何利用竞价节点加速任务执行，减少、甚至是消除异常节点带来的影响。这是任务执行加速部分的需要解决的问题。通过结合计算复制、投机执行等策略，任务执行加速组件根据异常节点情况利用竞价实例类型的计算资源加速异常节点上任务的完成，减少异常节点带来的影响进而避免整体作业进度的拖慢。
\begin{figure}
  \centering
  \includegraphics[width=1.0\textwidth]{NO2_arch.pdf}
  \caption{系统架构}
  \label{figure:no2arch}
\end{figure}

通过仔细设计接口，整个任务调度器保持了同作业调度器的独立性。这有利于用户根据自身需求选择不同的作业调度器。如图 \ref{figure:no2arch} 所示，任务调度器和ProActive作业调度器的接口部分只有获取一个作业的任务状态信息和发送任务管理命令。这些需求可以被任何作业调度器的控制接口满足。

下面将详细介绍系统的两个主要组成部分————异常节点检测组件和任务执行加速组件。

\subsection{异常节点检测}
\label{subsec:no2_trace}
异常节点检测的实现基于对程序的插桩跟踪和对跟踪信息的分析。程序跟踪借助于二进制代码插桩实现，分为两个阶段：函数采样信息统计和插桩点选择。函数采样是离线进行的，无需考虑插桩开销。采样过程需要对插桩后的程序多次执行，覆盖了程序中的所有函数。插桩后的二进制代码通过执行大量真实的输入数据获得所有函数的调用次数信息。基于这些统计信息，插桩点选择器可以过滤被频繁调用函数，避免运行时过高的性能开销。最终用于任务进度跟踪的插桩点覆盖了绝大多数函数，但将插桩带来的运行时开销降到了极低。由于无法根据任务进度跟踪直接得出任务执行进度的准确信息，我们需要根据所有并发任务的进度跟踪信息筛选出潜在的异常节点。异常分析模块的任务就是根据大量任务在执行过程中的由插桩点返回的信息判断是否有异常节点存在。在 \label{subsec:no2_clustering} 节给出了基于机器学习中常用的聚类分析算法的一个简单、有效的发现异常节点的方法。

\subsubsection{程序跟踪插桩工具}
\label{subsec:no2_inst}
在实际生产系统中使用二进制代码插桩跟踪程序的执行进度主要有两个挑战。一个挑战是性能开销，即使是轻量级的静态二进制插桩也可能带来数十个百分比的执行时间开销。另一个挑战是如何根据跟踪信息推测执行进度，这里的难点在于：1）在二进制代码中通过插桩工具埋下的程序跟踪点不是完全均匀一致的分布在整个执行过程中的；2）即使程序跟踪点在程序执行过程中均匀的被触发，仍然不能预测出任务已经完成了多少，还要执行多久。

以下载一个文件为例：如果下载进度条一分钟后显示已经完成了50\%，很明显任务已经完成了一半并且在一个稳定的网络带宽下可能还需一分钟的时间。这就是数据密集型任务的进度预测的基本思路。但对于计算密集型任务来说，二进制程序插桩只能得到程序执行过程中触发了哪些插桩点的信息，无法得知程序执行的绝对进度。没有了类似数据密集型任务输入输出与执行进度相关的假设，计算密集型任务的执行进度很难通过二进制代码插桩进行预测。二进制代码插桩只能作为提供程序执行跟踪信息的手段，而实际上大量并发任务的异常节点也不必非要预测任务的绝对执行进度。在本节我们重点讨论二进制代码插桩给程序执行带来的性能问题，异常节点检测则交由另一个模块根据大量并发任务执行的跟踪信息分析得出。

通过对多个计算密集型程序的二进制代码插桩和观察，可以得出两个发现：1）程序中不同的函数处在不同的调用层次；2）相同层次的函数被调用的频率相近，少数底层的函数被调用的极为频繁占用了大多数执行时间。表\ref{table:inst-stats}给出了插桩了全部函数入口点的ImageMagick动态链接库的函数调用次数统计信息。该函数库中有超过1060个函数，其中只有33个函数在多次执行中被调用超过10000次。
\begin{table*}[]
\caption{ImageMagick函数调用信息统计}
\label{table:inst-stats}
\begin{center}
\begin{tabular}{r|r|l}
\hline
调用次数 & 函数个数 & 函数举例 \\
\hline
above $10^7$ & 6 & CopyMagickMemory \\
$10^6$ - $10^7$ & 16 & GetCacheNexus \\
$10^5$ - $10^6$ & 2 & LocaleCompare \\
$10^4$ - $10^5$ & 9 & GetNexus \\
$10^3$ - $10^4$ & 10 & AddValueToSplayTree \\
$10^2$ - $10^3$ & 17 & FormatMagickStringList \\
$10^1$ - $10^2$ & 78 & NewSplayTree \\
$0$    - $10^1$ & 922 & GaussianBlurImage \\
\hline
\end{tabular}
\end{center}
注意：每个调用次数量级只给出了一个函数作为例子。
\end{table*}

函数进入／退出点，和基本块（Basic Block）是常用的二进制代码的程序插桩点。理想的程序执行跟踪是对所有这些插桩点进行插桩，以实现更好的代码覆盖效果。然而，二进制代码程序插桩的开销明显是和埋下的插桩点数量成比例的。通过选择相对粗力度的插桩可以跳过少部分底层函数，从而去掉了大部分的插桩开销。为了能够准确跟踪程序执行，二进制代码的插桩需要足够的覆盖程度。如何在保证足够大范围的插桩覆盖的要求下达到最低的插桩开销？下面给出了基于函数调用次数统计的程序跟踪插桩方法。如图 \ref{figure:tracing}所示，整个程序跟踪插桩的核心有两点：1）跟踪插桩点的选择；2）插桩点触发时执行的操作。
\begin{figure}
  \centering
  \includegraphics[width=1.0\textwidth]{NO2_tracing.pdf}
  \caption{程序跟踪插桩}
  \label{figure:tracing}
\end{figure}

插桩点选择方法首先对二进制代码中的所有函数埋下插桩点，纪录每个函数的调用情况。然后多次执行插桩后的程序并统计函数调用次数信息。通过多次执行，不同的调用层次的函数被区分开来。所有函数被调用次数的均值可以作为一个判断函数是否属于被频繁调用的底层函数的标准。所有大于这个均值的调用次数的函数，在最终的用于跟踪程序执行进度的插桩点选择中得以跳过。对于编程良好的程序，这样的自动插桩点选择方法可以同时保证足够大的执行进度跟踪覆盖和足够低的运行时开销。

在每个选定的程序插桩点可以插入一段代码，这段代码就是插桩点触发时需要执行的操作。对于程序执行的跟踪，在所有选定的函数入口进行插桩可以纪录下该函数形成函数调用的跟踪信息。由于这里程序跟踪的最终目标是在大量并发任务中检测潜在的异常节点，在插桩点执行的操作可以简化为将一个插桩点计数器加一。这样在每个插桩点的运行开销就大大的减少了。

\subsubsection{异常分析}
\label{subsec:no2_clustering}
对于计算密集型并行任务的加速来说，第一个首要的目标是找出异常节点。进行二进制插桩后的程序在各个节点执行，大量的并行任务运行中会提供程序的跟踪信息给异常分析模块。虽然没有任务执行的绝对进度信息，通过比较所有并行任务的跟踪信息还是可以对潜在的异常节点加以区分。这里使用统计分析和数据挖掘中常用的聚类分析方法对各个节点返回的程序跟踪信息进行聚类。对于大规模并行任务节点的程序跟踪信息的聚类分析基于如下假设：
\begin{itemize}
\item 在海量并行任务中，异常节点只占很少的一部分。
\item 作业的分割基本保持均匀，即所有任务的规模大致相同。
\item 集群中的服务器节点异常以非确定的方式出现且过一段时间可能恢复正常。
\end{itemize}

异常节点由于这样或者那样的原因执行缓慢，在程序跟踪的信息上同正常节点会表现出明显的（甚至是数量级上的）差距。这里使用大规模并行任务进度跟踪反馈的插桩点计数器信息提取每个任务的两个特征作为聚类依据，使用 K-means 聚类分析算法对正常节点和异常节点加以区分。这两个特征分别是插桩点计数器累积值和最近一个程序跟踪信息周期的插桩点计数器增量。它们基本反映了任务执行的即时状态。图 \ref{figure:clusteringexample} 给出了一个基于这两个特征进行聚类的例子。
\begin{figure}
  \centering
  \includegraphics[width=1.0\textwidth]{clusteringexample.pdf}
  \caption{一个对并行任务程序跟踪信息使用K-means进行二类聚类分析的例子}
  \label{figure:clusteringexample}
\end{figure}

程序跟踪信息中插桩点计数器的值可用于在大量并发任务中比较相对的快慢，而最近一个反馈周期的插桩点计数增量体现的则是最近一小段时间某个任务的执行状态。单纯的使用插桩点计数器的值可能无法发现在任务执行过程中出现异常的节点，因此结合这两个参数可以在把握大量并发任务整体执行状态的同时迅速的找出可疑的异常节点。如图 \ref{figure:clusteringexample} 所示，一个简单的 $k = 2$ K-means 聚类可以大致将代表任务执行状态的点分为两类。显然可以判断出，图 \ref{figure:clusteringexample} 中左下角的 $A$ 点极有可能代表一个异常节点的任务状态。对于图 \ref{figure:clusteringexample} 中的 $B$，$C$，$D$ 点，只能认为它们有可能是异常节点。对于任务执行加速的目标来说，可以接受误报（False Positive），但不能接受漏报（False Negtive）。因为误报只会损失一些计算资源，而漏报则会直接贻误执行加速的时机进而影响作业完成时间。所以，在计算资源允许的情况下合理的策略是对所有潜在的异常节点都通过备份执行实现容错。
\begin{figure}
\rule[-.2pt]{0.9\textwidth}{0.9pt}

\textbf{Algorithm: outlierClustering}

\rule[-.2pt]{0.9\textwidth}{0.5pt}

\begin{algorithmic}[1]
\Require{$traces$}
\Ensure{$outliers$}

\State $clusters\gets kmeans(traces, 2)$
\State $outliers\gets[]$
\If{$\left|clusters[1].centroid - clusters[2].centroid\right| \gg 0$}
    \If{$clusters[1].size \ll clusters[2].size$}
        \State $outliers\gets [clusters[1], outlierClustering(clusters[2])]$
    \ElsIf{$clusters[1].size \gg clusters[2].size$}
        \State $outliers\gets [clusters[2], outlierClustering(clusters[1])]$
    \EndIf
\EndIf
\State \Return{$outliers$}
\end{algorithmic}
\rule[-.2pt]{0.9\textwidth}{0.8pt}
\caption{异常节点聚类算法}\label{fig-outlier-algo}
\end{figure}

图 \ref{fig-outlier-algo} 给出了一个异常节点的聚类算法，该算法基于 K-means 聚类算法。由于 K-means 算法对初值的选取比较敏感，而这里聚类的目标是将异常节点（即两个特征值都偏小）和正常节点（即两个特征值都偏大）分成两类。因此可以用所有点中两个特征值的最小值作为一类初始聚类中心，所有点中两个特征值的最大值作为另一类初始聚类中心。如前文所述，异常节点检测的目标是报告可疑的异常节点。为了减少漏报，可以接受一定程度的误报。因此，在第一次 K-means 聚类后，可以对被认为不是异常节点的一类再进行一个 K-means 聚类，以过滤掉图 \ref{figure:clusteringexample} 中的类似 $D$ 点的情形。这样可以保证很大程度上的不漏报。

\subsection{任务执行加速}
在异常节点检测组件给出了潜在异常节点的情况下，可以利用竞价计算实例低成本的执行一个和潜在异常节点同样的任务。这样通过对同一个计算任务的多副本执行（Computation Replication），避免了某个节点上可能的异常拖慢整体作业执行进度。由于竞价实例的申请和启动需要几分钟甚至十几分钟的时间，在发现潜在的异常节点后再去申请竞价实例显然就丧失了加速执行的机会。因此系统中需要维护一个竞价实例资源池，这样在需要对计算任务增加一个执行副本时可以将竞价实例立即投入使用。如图 \ref{figure:spotpool} 所示，海量并行任务运行在按需实例集群中，竞价实例资源池负责提供需要投机执行时的计算资源。由于竞价实例的不稳定性，资源池需要从同地理区域内的多个可用区申请竞价实例以避免云平台回收竞价实例时造成无竞价实例可用的情况。这样当某个可用区因为竞价实例市场价格波动回收资源时，系统维护的竞价实例资源池可以通过在其他可用区申请新的竞价实例资源补充进来以保证资源池中的有足够的竞价实例。如果所有可用区的竞价实例市场价格均升高超过了相应按需实例的价格，则没有必要再使用竞价实例计算资源加速按需实例上的大规模并行任务了。
\begin{figure}
  \centering
  \includegraphics[width=1.0\textwidth]{spotpool.pdf}
  \caption{按需实例集群和竞价实例资源池}
  \label{figure:spotpool}
\end{figure}

\subsubsection{双副本执行策略}
在某个节点可能存在异常的情况下，将其上执行的相同任务在其他节点冗余执行以期容错的机制这里之称为多副本执行。当多个执行副本中的一个完成任务时，即可停止其他副本的执行。这类方法在Hadoop中被称为`` 投机执行''（Speculative Execution）。Hadoop 中的投机执行是指集群中一些节点存在空闲的时间槽（Time Slot），可以用于执行一些在其它节点执行的任务。这样一旦该任务在另一个节点上执行缓慢，就可以使用在该点上的执行结果加快作业完成。利用多副本执行加速大规模并行任务在策略上有一些直观的经验规则：
\begin{enumerate}
\item 对进度最慢的异常节点分配最高的多副本执行优先级，显然在可用的计算资源有限的情况下这是最优的选择。
\item 尽早对潜在异常节点发起投机执行。多副本执行的目标是尽量减少作业完成时间，尽早执行意味着更好的提早完成的机会。
\item 针对某个任务多副本执行时，由于比其它任务开始的晚，为了加快执行速度在允许的情况下可以将该任务分成若干个子任务交由多个节点执行。
\end{enumerate}

在本系统中冗余执行时增加一个副本用于容错，可以称之为双副本执行策略。

任务加速执行的算法主要部分的伪代码如图 \ref{fig-acc-algo} 所示，当用户提交作业后，任务执行加速器作为一个守护进程运行在管理节点上。该算法定期的获取各个节点上执行的任务的程序跟踪反馈信息，通过聚类分析找出其中潜在的异常节点。对于可能是异常节点上的任务，进行该任务的双副本执行策略。对于双副本执行的任务，一旦有一个任务副本执行完成，即可停止另一个副本的执行。
\begin{figure}
\rule[-.2pt]{0.9\textwidth}{0.9pt}

\textbf{Algorithm: TaskAccelerating}

\rule[-.2pt]{0.9\textwidth}{0.5pt}

\begin{algorithmic}[1]
\Require{instance of the $job$, and sleep $interval$}
\Ensure{the job's state $job.state$}

\State $shards\gets 2$
\While{$job.state\not=FinishedOrFaulty$}
    \If{$job.finished\_tasks\not=nil$}
        \State $shards\gets job.finsished\_tasks.size + 1$
    \EndIf
    \State $tasks\gets job.unfinished_tasks$
    \State $outliers\gets outlierClustering(tasks.traces)$
    \For{$outlier \in outliers$}
        \If{$! outlier.task.replicated$}
            \If{$outlier.task.divisible$}
                \State $shards\gets min(shards, outlier.task.pieces)$
                \State $r\gets job_submit(task\_split(outlier.task, shards))$
            \Else{}
                \State $r\gets job_submit(outlier.task)$                
            \EndIf
            \State $replications\gets [replications, r]$
        \EndIf
    \EndFor
    \State $sleep(interval)$
    \State $job.update()$
    \For{$r \in replications$}
        \If{$r.state = Finished$}
            \State $kill(r.outlier.taskid)$
        \ElsIf{$r.outlier.state = Finished$}
            \State $kill(r.jobid)$
        \EndIf
    \EndFor
\EndWhile
\end{algorithmic}
\rule[-.2pt]{0.9\textwidth}{0.8pt}
\caption{双副本执行算法}\label{fig-acc-algo}
\end{figure}

在图 \ref{fig-acc-algo} 所示的算法中，作为守护进程获取各个任务的程序跟踪信息的频率应该保证不影响ProActive作业管理器的正常执行。在需要针对某个任务增加执行副本时，如果任务可分，图 \ref{fig-acc-algo} 所示算法默认将任务拆分为两个子任务执行，在整个作业中已经有任务完成时将任务拆分为更多的子任务以减少任务完成所需时间。当然这要考虑作业的实际情况，在条件允许的情况下进行拆分。

\subsubsection{计算资源利用率优化}
在发现潜在异常节点后，除了使用竞价实例进行针对性的双副本执行，还可以利用系统中空闲的按需实例进行这样的冗余计算。这种情况可能出现在该节点已经执行完被分配的任务，但整个作业还没有完成的情况。联系图 \ref{fig-acc-algo} 中所示算法，随着部分节点完成任务后开始增加副本执行的任务拆分个数就是基于这一点考虑。

在用户提交作业后向各个节点分发任务前，由于还没有潜在异常节点的出现竞价实例将处于空闲状态。这部分空闲的计算资源也可以用来进行纯粹的``投机执行''，即在不知道各个节点状态的情况下冗余执行一些任务的副本。由于竞价实例资源池一般远小于按需计算实例的规模，因此投机执行只能针对部分节点。一个简单的策略是选择上次作业执行过程中出现的异常节点，如果还有剩余的竞价实例则可以随机制定。在作业开始执行后出现异常节点时，如果恰好有对应的备份执行节点且正常则不用再备份执行该任务。如果没有对应的备份执行节点，可以停掉某个两个任务备份都正常执行的相应竞价节点上的任务用于提供给新出现的异常节点做任务备份执行。

\section{系统实现}
\label{subsec:no2_impl}
为了更好的理解，本节对系统中一些重要的实现细节加以解释。开发中使用的技术和一些背后的实现技巧也进行了简短地介绍。

二进制插桩部分基于DynInst \cite{Dyninst-Deconstruction} 插桩库的静态插桩实现。DynInst 是一个支持对二进制代码进行静态插桩，或对运行中的进程进行动态插桩的工具函数库。它提供了一个构建插桩工具和应用的机器无关的接口。插桩点选择部分对函数调度次数的统计基于DynInst的一个使用例程，CodeCoverage \cite{codecoverage}。
	
对于插桩点选择器，有三个代码片段（Code Snippet）插桩到程序中：初始化部分代码片段插桩到程序的开始，用于创建一些数据结构用于统计所需信息；最为常用的代码片段插桩到所有函数的入口点，用于纪录每一次函数调用；最后一个代码片段插桩到程序的结束，用于将函数统计信息保存到一个文件。同样有三个代码片段用于最终的任务进度跟踪插桩，初始化和结束部分用于申请和释放共享内存。最常用的代码片段负责将程序跟踪插桩计数加一。

任务调度的投机执行部分基于 ProActive Scheduler \cite{pascheduling} 实现。通过控制脚本，任务调度器可以同ProActive的作业调度器进行交互。控制脚本是JavaScript风格的语言，解释引擎基于集成于Java SE发行版的 Rhino \cite{Rhino:2016} 脚本引擎。通过控制脚本可以在运行时调用Java实现的ProActive作业调度器的对象和方法。

任务调度根据异常节点聚类结果选择需要进行投机执行的任务。对于每个异常节点，生成一个紧急作业并给予一个相对普通ProActive作业更高的优先级。每个紧急作业可能包含一个或多个需要执行的任务，所有这些紧急作业按照投机优先级顺序提交给作业调度器。通过在作业描述中声明执行节点选择并提供节点选择脚本可以避免投机执行的任务被再次提交到一个异常节点。可以根据任务的大小选择调整异常节点检测和执行加速的间隔，避免过于频繁的交互对作业调度器造成的干扰。程序跟踪信息只有插桩点的计数，所占用的内存和传输带宽非常小，对性能的影响可以忽略不计。

在整个实现中还提供了三个Shell脚本用于任务分割，本地代码封装，以及结果合并。Shell脚本将被提交给作业调度器作为正常作业执行。以一个图片渲染的作业为例，这个作业包括三个部分：1、分割图片成许多小图，2、对每个小图片进行某种效果的渲染，3、合并渲染好的小图片。这三个阶段和本节提供的三个脚本是一致的。用户只需增加一个切割图片的命令到任务分割脚本中和一个合并图片的命令到结果合并脚本中，这对于其他作业可能是不必要的。一些默认的步骤，如：拷贝分割后的输入文件到任务执行节点，也可以根据具体情况进行修改。在本地代码封装脚本中，本地程序通过一条命令执行。用于传输任务跟踪信息的守护进程也在这个脚本中启动。用户可以极为灵活的使本地程序得以大规模并行。当然，在整个实现中，不提供文件传输、数据放置等服务。这些可以交由集群自身的网络文件系统等实现。

为了更好的程序执行性能，程序的插桩部分使用共享内存将结果传递给传输任务进度跟踪信息的守护进程，通过对内存的读写实现了纪录程序跟踪数据的目的。这样每次程序执行过程中遇到插桩点时只引入了内存写操作，相对文件读写大大降低了性能开销。

\section{系统评测}
\label{sec:no2_eval}
通过一系列在云平台中展开的实验，本节给出了系统性能等方面的评测结果。系统部署在 Amazon EC2 云平台的 ``us-east1'' 区域，使用 StarCluster \cite{starcluster} 将虚拟机计算实例组织成一个虚拟集群。StarCluster \cite{starcluster} 是一个 Amazon EC2 云平台上自动化虚拟集群构建、配置、管理的工具包，可以简化整个虚拟集群的部署过程。在虚拟集群中一个EBS被挂载在Master节点作为共享存储上以 NFS 文件系统的方式共享给集群中的所有节点。ProActive Scheduler 和本章的任务执行加速系统部署在虚拟集群的 Master 节点上，虚拟集群中的虚拟计算实例被以 SSHInfrastructure 类型节点资源的形式纳入到ProActive框架的管理调度中。虚拟集群中的计算资源包括200个按需计算实例，以及在该区域4个可用区维护的一个竞价实例计算资源池。虚拟集群中所有虚拟机实例的类型选用 ``linux.m1.small'' 类型节点。该类型实例有 1.7 GB 内存和一个虚拟 CPU 核（约一个 EC2 Compute Unit的计算能力），存储块设备为EBS。

实验中选用的代表性应用有两个：一个是生物信息学领域的 Cap3 \cite{Huang:1999:Cap3}，另一个是影像处理中常用的 ImageMagick \cite{imagemagick}。Cap3 是生物信息学中被比较常见的基因序列拼接组装程序，它的输入是许多FASTA格式 \cite{fasta} 的表达序列标签（Expressed Sequence Tag）序列文件。Cap3作业接受的输入一些需要尝试进行序列拼接的FASTA文件，每个Cap3任务处理这样的一个或若干个文件。另一个应用 ImageMagick 是经典的开源影像处理工具，被广泛用于图像处理渲染等。其中的高斯模糊（Gaussian Blur）是一个常用的图像处理手段，在数学上看高斯模糊就是图像与正态分布（高斯分布）做卷积。高斯模糊能够减少图像中的噪点以及降低层次细节，常用于计算机视觉算法中的预先处理阶段，也被称为高斯平滑。实验中使用 Gaussian Blur 作为另一个应用案例，一个 Gaussian Blur 作业需要对大量的图片进行高斯模糊处理，每个任务需要处理一张或多张这样的图片。

评测中的第一个测试是针对程序跟踪带来的二进制代码插桩性能开销的微基准测试，这关系到本章的任务执行加速器是否能用于实际的生产系统中。云计算平台的异常节点情况也通过实验数据加以验证。系统评测中最主要的指标是作业完成时间，它直接反映出系统加速和性能提升的效果。另外，系统的计算资源使用率和一个长期的成本开销也是系统评测关心的方面。

\subsection{程序插桩开销}
\label{sec:no2_overhead}
在系统中，程序跟踪是异常节点检测的基础。静态二进制代码插桩相比动态插桩的运行时开销已经小了很多，但如果对所有函数入口都埋入插桩点跟踪程序进度仍有不小的开销。这将使得系统在其它发面的优化大打折扣。基于对程序执行过程中函数调用层次的观察，本系统使用了一种基于采样的插桩点选择方法，在保证覆盖绝大多数函数的同时过滤掉了极少数调用频率特别高的函数，大大减少了程序跟踪插桩带来的开销。实验中对两个程序 Cap3 和 ImageMagick 使用两种不同的插桩方式得到的二进制代码在同一节点上执行相同的任务，没有插桩的原始二进制代码作为基线也在相同节点上执行了同一任务。不同二进制代码的执行时间如图 \ref{figure:inst_overhead} 所示，插桩全部函数入口点在两个程序的执行中约带来 10\% 左右的运行时开销，而系统中使用的基于采样的程序跟踪插桩几乎和原始二进制代码执行时间相同，增加的运行时开销约0.1\%。

\begin{figure}
  \centering
  \includegraphics[width=1.0\textwidth]{inst_overhead.pdf}
  \caption{程序跟踪的插桩开销}
  \label{figure:inst_overhead}
\end{figure}

实验结果显示本系统使用的基于采样的程序跟踪插桩开销足够小，对程序的执行性能没有明显影响，可以用于大规模实际生产系统中。

\subsection{异常节点情况}
\label{sec:no2_overhead}
云平台中异常节点的现象在一个大规模集群中非常普遍，有些时候相对正常节点在I/O、网络性能上又明显下降。在其上运行的程序可能受到严重影响。为了测试虚拟集群中的异常节点，这里向 ProActive 框架提交一个有200个相同任务的Cap3作业。在一天内不同阶段多次重复这个实验，可以发现异常节点的情况有所区别，但很多时间段内都存在少量的明显慢于其它节点任务执行速度的节点存在。这里选取其中有代表性的一次测试结果，具体如图 \ref{figure:outlier_cloud} 所示。
\begin{figure}
  \centering
  \includegraphics[width=1.0\textwidth]{cloud_outliers.pdf}
  \caption{云平台中200个节点在一次运行Cap3作业时的异常节点情况}
  \label{figure:outlier_cloud}
\end{figure}

从图 \ref{figure:outlier_cloud} 中可以看出，异常节点可能导致整个作业被拖慢两倍甚至更长的时间。异常节点出现的概率不高，但当虚拟集群中节点数量可观时出现少量异常节点的情况变得常见。对于大规模并行计算任务来说，考虑异常节点对整体作业进度的影响十分必要。

\subsection{性能改进}
\label{sec:no2_perf}
性能测试使用了虚拟集群中的200个按需计算实例，利用竞价实例作为多副本执行的计算资源。在实验过程中，通过向 ProActive Scheduler 提交包含 200 个任务的 Cap3 作业或 GaussianBlur 作业测试了在不使用本章提出的任务调度器、使用本章任务调度器但不使用任务初始阶段的投机执行策略，以及同时使用多副本执行策略和任务初始阶段投机执行策略三种系统配置下的系统性能。测试中所使用的作业任务规模大小接近：Cap3 任务为对一个FASTA格式文件中的基因序列进行拼接，不可继续进行分割；GaussianBlur 任务为对一张图片进行高斯模糊处理，根据实际计算中的近似算法可继续分割。

竞价实例计算资源池中的节点数量可以综合考虑成本因素，以及短期内异常节点出现比率设定。竞价实例用于进行多副本执行以消除异常节点的影响，当竞价实例节点数量不足可能导致有异常节点没有对应的执行副本仍拖慢作业完成进度。因此，在性能测试中首先要确定的是竞价实例计算资源池中所需的节点数量。在一段时间内，针对两个应用分别尝试提供占所有按需实例数量（本实验中为200个）不同百分比的竞价实例数用于多副本执行，在这个测试中不引入完成自身任务的空闲按需实例进行多副本执行。测得的作业完成时间如图 \ref{figure:replica_cap} 所示，在 Cap3 作业中有 3\%（6个）的竞价实例用于多副本执行就很好的抑制了异常节点造成的影响，在 Gaussian 作业中则需要至少8个节点用于多副本执行才起到减少作业完成时间的效果。这是因为 GaussianBlur 任务可以进行再次拆分，每次多副本执行都会使用更多的计算节点。虽然在用于多副本执行的节点数达到 4\% 之后才起到了消除异常节点的效果，但通过对任务拆分加快了任务执行进一步减少了作业完成时间从而得到了比 Cap3 作业更好的性能提升。根据上述测试结果，接下来的性能测试中在竞价实例资源池中维护 6\%（12个）的计算资源。为保证测试数据的准确性，在一段时间内相同的实验被重复多次，最后的结果取平均值和最小、最大值。实验结果如图 \ref{figure:completiontime_cloud} 所示。
\begin{figure}
  \centering
  \includegraphics[width=1.0\textwidth]{replica_cap.pdf}
  \caption{用于多副本执行的竞价实例数同作业完成时间的关系}
  \label{figure:replica_cap}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=1.0\textwidth]{cloud_completiontime.pdf}
  \caption{虚拟集群中的ProActive作业完成时间比较}
  \label{figure:completiontime_cloud}
\end{figure}

作业完成时间完全由执行最慢的任务决定。从图 \ref{figure:completiontime_cloud} 中可以看出，实验中ProActive计算框架的平均作业完成时间远远大于最好情况下的作业完成时间，这说明在大规模并行任务执行中异常节点对整体作业执行带来的拖慢影响十分严重。在使用了多副本执行策略后，Cap3 作业的平均完成时间被有效缩减了超过 20\%。由于 Cap3 任务不可继续分割，多副本执行策略无法通过再次分割任务的方式加快任务执行。实验结果上看，在多副本执行策略下 Cap3 作业的平均完成时间同没有异常节点的最好情况仍有一段差距。因为，在发现异常节点时副本执行的任务已经落后于正常节点。GaussianBlur 作业的平均执行时间在使用多副本执行策略后将性能提升了超过 40\%，接近作业执行时间的最好情况，基本消除了异常节点带来的影响。这是因为虽然发现异常节点时已经落后于正常节点，GaussianBlur 任务可以通过进一步分割减少完成任务所需的时间。如图 \ref{figure:completiontime_cloud} 所示，在任务初始阶段的投机执行策略只在 Cap3 作业执行中带来了少量的性能提升，对于 GaussianBlur 作业则完全没有效果。虽然任务初始阶段的投机执行有潜在的性能优化机会，但由于异常节点出现的不确定和偶发性其所能带来的性能提升在实验中并不明显。在任务不可分割的情况下，能一定程度上进一步减少异常节点造成的拖慢作业完成时间影响。

\subsection{资源使用率与成本开销}
\label{sec:no2_usage}
在进行性能测试的同时，ProActive Resource Manager 统计的CPU使用率也能一定程度上反映作业执行的效率。如图 \ref{figure:resourceusage_cloud} 所示，在大规模并行任务执行过程中，异常节点不仅拖慢了整体作业完成进度还造成了大量计算资源的空闲和浪费。在两个作业的执行中，均只有约 50\% 左右的CPU使用率。使用多副本执行和任务初始阶段投机执行的策略，加快了作业完成进度，减少了计算资源的空闲时间。在任务可再次分割的情况下，更是能够充分利用已经完成任务执行的空闲节点计算资源。多副本执行策略使 Cap3 作业的执行中 CPU 使用率增加到了约 75\%，在 Gaussian 作业中CPU使用率更是超过了 90\%。
\begin{figure}
  \centering
  \includegraphics[width=1.0\textwidth]{cloud_usage.pdf}
  \caption{虚拟集群在ProActive作业执行中的CPU使用率比较}
  \label{figure:resourceusage_cloud}
\end{figure}

在计算成本开销方面，从长期的 Amazon EC2 云平台竞价实例市场价格的历史数据看，竞价实例的成本约为相同类型的按需成本的五分之一到十分之一。以本实验中使用的``linux.m1.small'' 类型来说，对于一个有200个按需计算实例的虚拟集群来说，10个竞价实例的计算成本只有约虚拟集群成本的 1\%。

\section{本章讨论}
本章详细介绍了利用竞价云加速大规模计算密集型并行任务的方法，基于程序跟踪和聚类分析等手段实现了对海量并发计算密集型任务的异常节点早期检测，通过多副本执行等策略实现了作业完成时间的缩减，消除了异常节点造成的影响。该方法的有效性在系统评测中得到了验证，但在实际应用中仍有一些需要注意的地方。

\subsection{系统适用性}
本章提出的海量计算密集型并行任务处理加速方法，针对的是短任务（任务执行时间在分钟级别），解决的是云计算平台虚拟集群中偶发性的节点异常拖慢作业完成进而影响工作流进度的问题。对于执行时间很长的批处理任务（任务执行时间在小时级别）可能并不适合使用这个方法，因为多副本执行一个长任务的代价相对短任务大大增加。对于长任务和实时性要求不高的任务可以选择通过检查点、任务迁移等技术手段加以解决。

\subsection{竞价节点能否替代按需节点}
另一个需要强调的问题是关于对竞价节点的使用。既然系统能够处理大规模并行任务处理中的异常节点拖慢作业进度问题，将虚拟集群中的按需实例全部或者部分换成同样成本但数量更多的竞价实例似乎能进一步提升系统并行能力。云计算平台异常节点的产生多种多样，包括：硬件故障、软件配置错误、共享I/O和网络带宽资源导致的竞争等。竞价节点潜在的不可靠性引入了一种新的节点异常，但这类异常完全不同于其它：1）竞价节点失效不是性能变差而是直接停机；2）竞价节点的异常不是偶发性、少量的，大量同一可用区相同竞价的竞价节点的失效是强相关的。这同本章介绍的任务调度器假设的系统中的异常节点只占很少一部分相违背。而针对大量的节点异常使用多副本执行策略时，大量新的执行副本同样面临执行过程中的异常节点问题。而引入相对按需实例很小比例的竞价实例则对性能提升的意义不大。事实上，这是另一个问题，即：在使用竞价实例执行计算任务时如何处理竞价不足的节点失效问题。相关的研究工作 \cite{Liu:2011:CMC:2170444.2170450, Andrzejak:2010:DMC:1906481.1906533} 针对不同的计算框架和任务提出了使用竞价实例同时保证系统正常运行的方法，但对于时间约束较强的工作流场景竞价节点仍不能代替按需节点。实际上本章的工作并不针对特定的计算资源类型，只要是大规模计算密集型并行任务中的异常节点拖慢作业整体进度的问题都可以应用本章的方法。

\subsection{成本收益分析}
对于本章要解决的问题，一个十分简单的处理方法是更加激进的进行副本执行策略。在全部任务开始执行的时候直接进行冗余执行，每个任务有两个副本来消除节点异常带来的影响。显然相对带来的性能提升，无论是使用按需实例还是竞价实例作为执行副本的计算资源都是不划算的。再考虑异常节点长期的出现频率，使用一定比例的按需实例作为执行副本的计算资源仍是一个很高的成本。相对应的，极为低廉的价格以及作为备用执行副本的用途让竞价实例成为了更好的选择。

\section{本章小节}
同以往的工作不同，本章提出了利用竞价云大规模计算密集型并行任务的异常节点拖慢作业进度的低成本解决方法。该方法的原型实现在ProActive计算框架上，引入了针对大规模计算密集型任务的异常节点检测方法。该方法通过组合基于二进制插桩的程序跟踪技术和聚类分析方法实现了对异常节点的早期发现。在程序跟踪方面，通过类似采样的插桩点选择在保证足够覆盖性的前提下将插桩的运行时开销从 10\% 降低到了 约 0.1\%。多副本执行的策略一定程度上消除了异常节点的影响，针对任务可继续分割的情况通过使用多次节点完成一个任务进一步减少了作业完成时间。针对两个典型应用的评测结果显示本章的工作实现了对大规模计算密集型任务的加速，性能提升在两个应用中分别超过 20\% 和 40\%。